# üöÄ UNIVERSAL STEAM SCRAPER (multi-device, resilient, staged)
# –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç: –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å, –Ω–µ—Å–∫–æ–ª—å–∫–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤, –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ, –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

import os
import csv
import time
import random
from concurrent.futures import ThreadPoolExecutor, as_completed
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By

# ---------------- CONFIG ----------------
DEVICE_ID = 1          # –Ω–æ–º–µ—Ä —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (1, 2, 3)
DEVICE_COUNT = 3       # –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤
MAX_THREADS = 5        # –ø–æ—Ç–æ–∫–æ–≤
BATCH_SIZE = 40        # —Å–∫–æ–ª—å–∫–æ —Å—Å—ã–ª–æ–∫ –ø–∞—Ä—Å–∏—Ç—å –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
OUTPUT_DIR = "results"
os.makedirs(OUTPUT_DIR, exist_ok=True)
PROGRESS_FILE = f"progress_{DEVICE_ID}.txt"
ERROR_LOG = f"errors_{DEVICE_ID}.log"
# ----------------------------------------

def init_driver():
    opts = Options()
    opts.add_argument("--headless")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-gpu")
    opts.add_argument("--disable-dev-shm-usage")
    return webdriver.Chrome(options=opts)

# ======================================================
#  –≠–¢–ê–ü 1: –°–ë–û–† –°–°–´–õ–û–ö (—Ä–∞–∑–¥–µ–ª—è–µ—Ç—Å—è –º–µ–∂–¥—É —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º–∏)
# ======================================================
def get_search_pages():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü –ø–æ–∏—Å–∫–∞"""
    base = "https://store.steampowered.com/search/?category1=998&page="
    pages = [f"{base}{i}" for i in range(1, 301)]  # –ø—Ä–∏–º–µ—Ä: 300 —Å—Ç—Ä–∞–Ω–∏—Ü
    return pages[DEVICE_ID-1::DEVICE_COUNT]

def collect_links_from_page(url):
    driver = init_driver()
    links = set()
    try:
        driver.get(url)
        time.sleep(random.uniform(1.5, 2.5))
        for it in driver.find_elements(By.CSS_SELECTOR, ".search_result_row"):
            href = it.get_attribute("href")
            if href:
                links.add(href.split("?")[0])
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}: {e}")
    finally:
        driver.quit()
    return list(links)

def collect_links():
    pages = get_search_pages()
    print(f"üß© –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ {DEVICE_ID}: {len(pages)} —Å—Ç—Ä–∞–Ω–∏—Ü –ø–æ–∏—Å–∫–∞")
    all_links = []
    with ThreadPoolExecutor(MAX_THREADS) as ex:
        futures = [ex.submit(collect_links_from_page, p) for p in pages]
        for f in as_completed(futures):
            all_links.extend(f.result())
    filename = f"links_part_{DEVICE_ID}.csv"
    with open(filename, "w", newline="", encoding="utf-8") as f:
        csv.writer(f).writerows([[x] for x in sorted(set(all_links))])
    print(f"üíæ –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ {DEVICE_ID}: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(all_links)} —Å—Å—ã–ª–æ–∫ –≤ {filename}")

# ======================================================
#  –≠–¢–ê–ü 2: –ü–ê–†–°–ò–ù–ì –ò–ì–† –° –í–û–ó–û–ë–ù–û–í–õ–ï–ù–ò–ï–ú
# ======================================================
def parse_game(link):
    driver = init_driver()
    try:
        driver.get(link)
        time.sleep(random.uniform(1.5, 3))
        title = driver.find_element(By.CSS_SELECTOR, ".apphub_AppName").text
        release = driver.find_element(By.CSS_SELECTOR, ".date").text
        price_el = driver.find_elements(By.CSS_SELECTOR, ".game_purchase_price, .discount_final_price")
        price = price_el[0].text if price_el else "N/A"
        return {"title": title, "release": release, "price": price, "url": link}
    except Exception as e:
        with open(ERROR_LOG, "a", encoding="utf-8") as ef:
            ef.write(f"{link} | {e}\n")
        return {"url": link, "error": str(e)}
    finally:
        driver.quit()

def get_completed_links():
    """–°—á–∏—Ç—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—Å—ã–ª–æ–∫"""
    if not os.path.exists(PROGRESS_FILE):
        return set()
    with open(PROGRESS_FILE, encoding="utf-8") as f:
        return set(x.strip() for x in f if x.strip())

def update_progress(link):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Å—Å—ã–ª–∫—É –≤ –ª–æ–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
    with open(PROGRESS_FILE, "a", encoding="utf-8") as f:
        f.write(link + "\n")

def parse_links():
    filename = f"links_part_{DEVICE_ID}.csv"
    if not os.path.exists(filename):
        print(f"‚ùå –ù–µ—Ç —Ñ–∞–π–ª–∞ {filename}. –°–Ω–∞—á–∞–ª–∞ —Å–æ–±–µ—Ä–∏ —Å—Å—ã–ª–∫–∏.")
        return

    with open(filename, encoding="utf-8") as f:
        links = [row[0] for row in csv.reader(f)]

    done = get_completed_links()
    pending = [x for x in links if x not in done]
    print(f"üß© –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ {DEVICE_ID}: {len(done)} –≥–æ—Ç–æ–≤–æ, {len(pending)} –æ—Å—Ç–∞–ª–æ—Å—å.")

    batch_num = 0
    for i in range(0, len(pending), BATCH_SIZE):
        batch = pending[i:i+BATCH_SIZE]
        results = []
        with ThreadPoolExecutor(MAX_THREADS) as ex:
            futures = [ex.submit(parse_game, link) for link in batch]
            for f in as_completed(futures):
                res = f.result()
                results.append(res)
                update_progress(res["url"])

        batch_num += 1
        out_file = os.path.join(OUTPUT_DIR, f"data_part_{DEVICE_ID}_{batch_num}.csv")
        with open(out_file, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=["title", "release", "price", "url", "error"])
            writer.writeheader()
            writer.writerows(results)
        print(f"üíæ {DEVICE_ID}: –°–æ—Ö—Ä–∞–Ω–µ–Ω —Ñ–∞–π–ª {out_file} ({len(results)} –∑–∞–ø–∏—Å–µ–π)")
        time.sleep(random.uniform(2, 5))

# ======================================================
#  –î–û–ü: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
# ======================================================
def merge_links():
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ links_part_X.csv –≤ –æ–¥–∏–Ω steam_links.csv"""
    all_links = set()
    for i in range(1, DEVICE_COUNT + 1):
        f = f"links_part_{i}.csv"
        if os.path.exists(f):
            with open(f, encoding="utf-8") as ff:
                all_links.update(row[0] for row in csv.reader(ff))
    with open("steam_links.csv", "w", newline="", encoding="utf-8") as f:
        csv.writer(f).writerows([[x] for x in sorted(all_links)])
    print(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ {len(all_links)} —Å—Å—ã–ª–æ–∫ –≤ steam_links.csv")

def merge_results():
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ CSV —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"""
    all_rows = []
    for root, _, files in os.walk(OUTPUT_DIR):
        for file in files:
            if file.endswith(".csv"):
                path = os.path.join(root, file)
                with open(path, encoding="utf-8") as f:
                    reader = csv.DictReader(f)
                    all_rows.extend(list(reader))
    with open("steam_full.csv", "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=["title", "release", "price", "url", "error"])
        writer.writeheader()
        writer.writerows(all_rows)
    print(f"‚úÖ –í—Å–µ —á–∞—Å—Ç–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã –≤ steam_full.csv ({len(all_rows)} –∑–∞–ø–∏—Å–µ–π)")

# ======================================================
#  –û–°–ù–û–í–ù–û–ô –í–•–û–î
# ======================================================
if __name__ == "__main__":
    # --- –≠—Ç–∞–ø 1: —Å–±–æ—Ä —Å—Å—ã–ª–æ–∫ ---
    # collect_links()

    # --- –≠—Ç–∞–ø 2: –ø–∞—Ä—Å–∏–Ω–≥ (—Å –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º) ---
    parse_links()

    # --- (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –ø–æ—Å–ª–µ –≤—Å–µ—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤) ---
    # merge_links()
    # merge_results()
